{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXsu8MxUVAKT"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kXr4Cxh2VAKZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Eq-7JCT6VAKa"
      },
      "outputs": [],
      "source": [
        "import spacy \n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItxQ587VVAKb"
      },
      "source": [
        "### Read reviews data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "q1pr6bbsVAKb"
      },
      "outputs": [],
      "source": [
        "con=open(\"./Samsung.txt\",'r', encoding=\"utf-8\")\n",
        "samsung_reviews=con.read()\n",
        "con.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "f4GyRJMEVAKb",
        "outputId": "29fcc27e-8558-4e67-bec3-b677797f4601"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "46355"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(samsung_reviews.split(\"\\n\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU4ZvurwVAKc"
      },
      "source": [
        "### Dataset is a text file where each review is in a new line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "bPT-wYC2VAKd",
        "outputId": "93ff4281-69f0-4cfc-b686-a64e9cf439ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['It works good but it goes slow sometimes but its a very good phone I love it',\n",
              " 'Great phone to replace my lost phone. The only thing is the volume up button does not work, but I can still go into settings to adjust. Other than that, it does the job until I am eligible to upgrade my phone again.Thaanks!',\n",
              " 'I originally was using the Samsung S2 Galaxy for Sprint and wanted to return back to the Samsung EPIC 4G for Sprint because I really missed the keyboard, I really liked the smaller compact size of the phone, and I still needed some of the basic functions of a smart phone (i.e. checking e-mail, getting directions, text messaging) Because the phone is not as powerful as the newer cell phones out there, just be aware that the more applications you install the slower the phone runs and will most likely freeze up from time to time. But the camera works great, the video is great as well, and even the web browsing is decent and gives me what I need. I also notice that battery life lasts a little bit longer and charging the phone is much quicker than my Galaxy S2.',\n",
              " 'This is a great product it came after two days of ordering it. There was only one little blemish on the side,but who cares as long as the phone is fullly functional.i recommend this product to anyone reading this.',\n",
              " 'These guys are the best! I had a little situation with my item but they quickly fixed the issue. I was pleased and will definitely be buying another phon from them if I need one.',\n",
              " 'Ordered this phone as a replacement for the same model until my contract expires and I can get a new one. Seller confirmation said delivery could take up to 7 days. Seller sent out the phone within hours of receiving the order and I had the phone the next day. Phone looks better than described was able to transfer data from the old one to the new one with no problems. Highly recommend this seller',\n",
              " \"I was able to get the phone I previously owned...with a keyboard and touch screen. It's the best phone and I love it. I still had to clean the device with my service provider, but it was well worth it.\"]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samsung_reviews.split(\"\\n\")[3:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUi5gE7WVAKd"
      },
      "source": [
        "### Will our hypothesis hold on real world data? `Product features---POS_NOUN`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "yUx96iRtVAKg"
      },
      "outputs": [],
      "source": [
        "review1=samsung_reviews.split(\"\\n\")[0]\n",
        "review1=nlp(review1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKt6ZNPnVAKg"
      },
      "source": [
        "### Lets do nlp parse on part of one review in our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "gOCZxFp_VAKh",
        "outputId": "1465e5eb-d533-42dc-e890-c76dfa65d589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I --- I --- PRON\n",
            "feel --- feel --- VERB\n",
            "so --- so --- ADV\n",
            "LUCKY --- LUCKY --- NOUN\n",
            "to --- to --- PART\n",
            "have --- have --- AUX\n",
            "found --- find --- VERB\n",
            "this --- this --- DET\n",
            "used --- use --- VERB\n",
            "( --- ( --- PUNCT\n"
          ]
        }
      ],
      "source": [
        "for tok in review1[0:10]:\n",
        "    print(tok.text,\"---\",tok.lemma_,\"---\",tok.pos_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOBlgcu0VAKh"
      },
      "source": [
        "#### Real world data is usually messy, observe the words `found` and `used`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "yB1t1bPTVAKh"
      },
      "outputs": [],
      "source": [
        "pos = []\n",
        "lemma = []\n",
        "text = []\n",
        "for tok in review1:\n",
        "    pos.append(tok.pos_)\n",
        "    lemma.append(tok.lemma_)\n",
        "    text.append(tok.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "G3LDkWepVAKi",
        "outputId": "0e2c0671-4157-4ae6-a397-08ef8ad1dfdf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I</td>\n",
              "      <td>I</td>\n",
              "      <td>PRON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>feel</td>\n",
              "      <td>feel</td>\n",
              "      <td>VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>so</td>\n",
              "      <td>so</td>\n",
              "      <td>ADV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LUCKY</td>\n",
              "      <td>LUCKY</td>\n",
              "      <td>NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>to</td>\n",
              "      <td>to</td>\n",
              "      <td>PART</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>from</td>\n",
              "      <td>from</td>\n",
              "      <td>ADP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>them</td>\n",
              "      <td>they</td>\n",
              "      <td>PRON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>again</td>\n",
              "      <td>again</td>\n",
              "      <td>ADV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>!</td>\n",
              "      <td>!</td>\n",
              "      <td>PUNCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>!</td>\n",
              "      <td>!</td>\n",
              "      <td>PUNCT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>86 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     text  lemma    pos\n",
              "0       I      I   PRON\n",
              "1    feel   feel   VERB\n",
              "2      so     so    ADV\n",
              "3   LUCKY  LUCKY   NOUN\n",
              "4      to     to   PART\n",
              "..    ...    ...    ...\n",
              "81   from   from    ADP\n",
              "82   them   they   PRON\n",
              "83  again  again    ADV\n",
              "84      !      !  PUNCT\n",
              "85      !      !  PUNCT\n",
              "\n",
              "[86 rows x 3 columns]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nlp_table = pd.DataFrame({'text':text,'lemma':lemma,'pos':pos})\n",
        "nlp_table.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "FEXKFzlPVAKi",
        "outputId": "15fa5020-0bcb-4ba1-8d31-938fc204de91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "lemma\n",
              "use           2\n",
              "feel          1\n",
              "find          1\n",
              "upgrade       1\n",
              "sell          1\n",
              "like          1\n",
              "fall          1\n",
              "want          1\n",
              "thank         1\n",
              "appreciate    1\n",
              "say           1\n",
              "recommend     1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Get most frequent lemma forms of nouns\n",
        "nlp_table[nlp_table['pos']=='VERB']['lemma'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-uR8q-LVAKi"
      },
      "source": [
        "#### It seems possible that if we extract all the nouns from the reviews and look at the top 5 most frequent lemmatised noun forms, we will be able to identify `What people are talking about?`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOvqBuwgVAKj"
      },
      "source": [
        "### Lets repeat this experiment on a larger set of reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "RsDUv3X1VAKj"
      },
      "outputs": [],
      "source": [
        "nouns = []\n",
        "for review in samsung_reviews.split(\"\\n\")[0:100]:\n",
        "    doc = nlp(review)\n",
        "    for tok in doc:\n",
        "        if tok.pos_==\"NOUN\":\n",
        "            nouns.append(tok.lemma_.lower())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrVi3UPTVAKj"
      },
      "source": [
        "### Lets add some way of keeping track of time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "zNhp_45EVAKj",
        "outputId": "bf7700fd-7e6c-46a2-f8ad-e6282812b14c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:05<00:00, 199.60it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "have    397\n",
              "work    271\n",
              "use     216\n",
              "get     190\n",
              "love    165\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "nouns = []\n",
        "for review in tqdm(samsung_reviews.split(\"\\n\")[0:1000]):\n",
        "    doc = nlp(review)\n",
        "    for tok in doc:\n",
        "        if tok.pos_==\"VERB\":\n",
        "            nouns.append(tok.lemma_.lower())\n",
        "pd.Series(nouns).value_counts().head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "jai2hnfoVAKk",
        "outputId": "4d74cbee-10fe-444d-9c8d-f3a1a7f4ff2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "46355"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(samsung_reviews.split(\"\\n\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94gZ5gxLVAKk"
      },
      "source": [
        "### Did you notice anything? What do you think will be the time taken to process all the reviews?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "Op_ftvWyVAKk",
        "outputId": "3b9fbbd0-87f3-432b-df9d-0579267a250f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "782"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(46355//1000)*17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "230"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(46355//1000)*5 # for my computer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "VDMknUOXVAKl",
        "outputId": "fe2f2b6f-65d5-45e0-f58e-5cc9408ab0e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "782//60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "230//60 # for my computer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PsJmzrtVAKl"
      },
      "source": [
        "## Summary\n",
        "- POS tag based rule seems to be working well\n",
        "- We need to figure out a way to reduce the time taken to process reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf7AFwbiVAKl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "POS2.ipynb.txt",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
